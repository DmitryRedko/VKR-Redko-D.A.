{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;VOL&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230502</td>\n",
       "      <td>242.20</td>\n",
       "      <td>245.00</td>\n",
       "      <td>237.40</td>\n",
       "      <td>242.62</td>\n",
       "      <td>83246880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230503</td>\n",
       "      <td>242.85</td>\n",
       "      <td>242.99</td>\n",
       "      <td>234.00</td>\n",
       "      <td>235.77</td>\n",
       "      <td>76740930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>230504</td>\n",
       "      <td>236.51</td>\n",
       "      <td>239.74</td>\n",
       "      <td>236.05</td>\n",
       "      <td>238.89</td>\n",
       "      <td>53006840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230505</td>\n",
       "      <td>239.19</td>\n",
       "      <td>240.66</td>\n",
       "      <td>237.30</td>\n",
       "      <td>237.70</td>\n",
       "      <td>61314710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230508</td>\n",
       "      <td>238.65</td>\n",
       "      <td>239.86</td>\n",
       "      <td>237.36</td>\n",
       "      <td>238.27</td>\n",
       "      <td>47676110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>231106</td>\n",
       "      <td>269.00</td>\n",
       "      <td>273.87</td>\n",
       "      <td>268.62</td>\n",
       "      <td>273.42</td>\n",
       "      <td>29231770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>231107</td>\n",
       "      <td>273.08</td>\n",
       "      <td>274.78</td>\n",
       "      <td>272.20</td>\n",
       "      <td>273.31</td>\n",
       "      <td>32183320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>231108</td>\n",
       "      <td>273.53</td>\n",
       "      <td>278.35</td>\n",
       "      <td>273.28</td>\n",
       "      <td>278.15</td>\n",
       "      <td>58000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>231109</td>\n",
       "      <td>278.60</td>\n",
       "      <td>278.85</td>\n",
       "      <td>276.02</td>\n",
       "      <td>276.65</td>\n",
       "      <td>28258660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>231110</td>\n",
       "      <td>276.99</td>\n",
       "      <td>281.30</td>\n",
       "      <td>276.60</td>\n",
       "      <td>280.19</td>\n",
       "      <td>44600220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     <DATE>  <OPEN>  <HIGH>   <LOW>  <CLOSE>     <VOL>\n",
       "0    230502  242.20  245.00  237.40   242.62  83246880\n",
       "1    230503  242.85  242.99  234.00   235.77  76740930\n",
       "2    230504  236.51  239.74  236.05   238.89  53006840\n",
       "3    230505  239.19  240.66  237.30   237.70  61314710\n",
       "4    230508  238.65  239.86  237.36   238.27  47676110\n",
       "..      ...     ...     ...     ...      ...       ...\n",
       "132  231106  269.00  273.87  268.62   273.42  29231770\n",
       "133  231107  273.08  274.78  272.20   273.31  32183320\n",
       "134  231108  273.53  278.35  273.28   278.15  58000060\n",
       "135  231109  278.60  278.85  276.02   276.65  28258660\n",
       "136  231110  276.99  281.30  276.60   280.19  44600220\n",
       "\n",
       "[137 rows x 6 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_csv('train.csv',sep=';')\n",
    "data.drop(['<TICKER>','<PER>','<TIME>'],axis=1,inplace=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;VOL&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;_1d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_2d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_3d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_4d_ago</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;LOW&gt;_1d_ago</th>\n",
       "      <th>&lt;LOW&gt;_2d_ago</th>\n",
       "      <th>&lt;LOW&gt;_3d_ago</th>\n",
       "      <th>&lt;LOW&gt;_4d_ago</th>\n",
       "      <th>&lt;LOW&gt;_5d_ago</th>\n",
       "      <th>&lt;VOL&gt;_1d_ago</th>\n",
       "      <th>&lt;VOL&gt;_2d_ago</th>\n",
       "      <th>&lt;VOL&gt;_3d_ago</th>\n",
       "      <th>&lt;VOL&gt;_4d_ago</th>\n",
       "      <th>&lt;VOL&gt;_5d_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>216.51</td>\n",
       "      <td>227.50</td>\n",
       "      <td>215.70</td>\n",
       "      <td>227.06</td>\n",
       "      <td>154134860</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>238.89</td>\n",
       "      <td>235.77</td>\n",
       "      <td>...</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>234.00</td>\n",
       "      <td>237.40</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "      <td>76740930.0</td>\n",
       "      <td>83246880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>228.57</td>\n",
       "      <td>235.38</td>\n",
       "      <td>223.94</td>\n",
       "      <td>229.32</td>\n",
       "      <td>197037380</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>238.89</td>\n",
       "      <td>...</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>234.00</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "      <td>76740930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>231.05</td>\n",
       "      <td>232.47</td>\n",
       "      <td>226.15</td>\n",
       "      <td>229.29</td>\n",
       "      <td>69831820</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>...</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>230.54</td>\n",
       "      <td>231.75</td>\n",
       "      <td>228.52</td>\n",
       "      <td>231.70</td>\n",
       "      <td>48873370</td>\n",
       "      <td>229.29</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>...</td>\n",
       "      <td>226.15</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>69831820.0</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>232.40</td>\n",
       "      <td>232.86</td>\n",
       "      <td>229.57</td>\n",
       "      <td>230.62</td>\n",
       "      <td>36429340</td>\n",
       "      <td>231.70</td>\n",
       "      <td>229.29</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>...</td>\n",
       "      <td>228.52</td>\n",
       "      <td>226.15</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>48873370.0</td>\n",
       "      <td>69831820.0</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>269.00</td>\n",
       "      <td>273.87</td>\n",
       "      <td>268.62</td>\n",
       "      <td>273.42</td>\n",
       "      <td>29231770</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>269.68</td>\n",
       "      <td>268.35</td>\n",
       "      <td>...</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>266.87</td>\n",
       "      <td>268.60</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "      <td>26117980.0</td>\n",
       "      <td>33261680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>273.08</td>\n",
       "      <td>274.78</td>\n",
       "      <td>272.20</td>\n",
       "      <td>273.31</td>\n",
       "      <td>32183320</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>269.68</td>\n",
       "      <td>...</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>266.87</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "      <td>26117980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>273.53</td>\n",
       "      <td>278.35</td>\n",
       "      <td>273.28</td>\n",
       "      <td>278.15</td>\n",
       "      <td>58000060</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>...</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>278.60</td>\n",
       "      <td>278.85</td>\n",
       "      <td>276.02</td>\n",
       "      <td>276.65</td>\n",
       "      <td>28258660</td>\n",
       "      <td>278.15</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>...</td>\n",
       "      <td>273.28</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>58000060.0</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>276.99</td>\n",
       "      <td>281.30</td>\n",
       "      <td>276.60</td>\n",
       "      <td>280.19</td>\n",
       "      <td>44600220</td>\n",
       "      <td>276.65</td>\n",
       "      <td>278.15</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>...</td>\n",
       "      <td>276.02</td>\n",
       "      <td>273.28</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>28258660.0</td>\n",
       "      <td>58000060.0</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <DATE>  <OPEN>  <HIGH>   <LOW>  <CLOSE>      <VOL>  <CLOSE>_1d_ago  \\\n",
       "5   2023-05-10  216.51  227.50  215.70   227.06  154134860          238.27   \n",
       "6   2023-05-11  228.57  235.38  223.94   229.32  197037380          227.06   \n",
       "7   2023-05-12  231.05  232.47  226.15   229.29   69831820          229.32   \n",
       "8   2023-05-15  230.54  231.75  228.52   231.70   48873370          229.29   \n",
       "9   2023-05-16  232.40  232.86  229.57   230.62   36429340          231.70   \n",
       "..         ...     ...     ...     ...      ...        ...             ...   \n",
       "132 2023-11-06  269.00  273.87  268.62   273.42   29231770          268.54   \n",
       "133 2023-11-07  273.08  274.78  272.20   273.31   32183320          273.42   \n",
       "134 2023-11-08  273.53  278.35  273.28   278.15   58000060          273.31   \n",
       "135 2023-11-09  278.60  278.85  276.02   276.65   28258660          278.15   \n",
       "136 2023-11-10  276.99  281.30  276.60   280.19   44600220          276.65   \n",
       "\n",
       "     <CLOSE>_2d_ago  <CLOSE>_3d_ago  <CLOSE>_4d_ago  ...  <LOW>_1d_ago  \\\n",
       "5            237.70          238.89          235.77  ...        237.36   \n",
       "6            238.27          237.70          238.89  ...        215.70   \n",
       "7            227.06          238.27          237.70  ...        223.94   \n",
       "8            229.32          227.06          238.27  ...        226.15   \n",
       "9            229.29          229.32          227.06  ...        228.52   \n",
       "..              ...             ...             ...  ...           ...   \n",
       "132          269.06          269.68          268.35  ...        267.20   \n",
       "133          268.54          269.06          269.68  ...        268.62   \n",
       "134          273.42          268.54          269.06  ...        272.20   \n",
       "135          273.31          273.42          268.54  ...        273.28   \n",
       "136          278.15          273.31          273.42  ...        276.02   \n",
       "\n",
       "     <LOW>_2d_ago  <LOW>_3d_ago  <LOW>_4d_ago  <LOW>_5d_ago  <VOL>_1d_ago  \\\n",
       "5          237.30        236.05        234.00        237.40    47676110.0   \n",
       "6          237.36        237.30        236.05        234.00   154134860.0   \n",
       "7          215.70        237.36        237.30        236.05   197037380.0   \n",
       "8          223.94        215.70        237.36        237.30    69831820.0   \n",
       "9          226.15        223.94        215.70        237.36    48873370.0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "132        268.50        267.60        266.87        268.60    20968810.0   \n",
       "133        267.20        268.50        267.60        266.87    29231770.0   \n",
       "134        268.62        267.20        268.50        267.60    32183320.0   \n",
       "135        272.20        268.62        267.20        268.50    58000060.0   \n",
       "136        273.28        272.20        268.62        267.20    28258660.0   \n",
       "\n",
       "     <VOL>_2d_ago  <VOL>_3d_ago  <VOL>_4d_ago  <VOL>_5d_ago  \n",
       "5      61314710.0    53006840.0    76740930.0    83246880.0  \n",
       "6      47676110.0    61314710.0    53006840.0    76740930.0  \n",
       "7     154134860.0    47676110.0    61314710.0    53006840.0  \n",
       "8     197037380.0   154134860.0    47676110.0    61314710.0  \n",
       "9      69831820.0   197037380.0   154134860.0    47676110.0  \n",
       "..            ...           ...           ...           ...  \n",
       "132    25499750.0    20587810.0    26117980.0    33261680.0  \n",
       "133    20968810.0    25499750.0    20587810.0    26117980.0  \n",
       "134    29231770.0    20968810.0    25499750.0    20587810.0  \n",
       "135    32183320.0    29231770.0    20968810.0    25499750.0  \n",
       "136    58000060.0    32183320.0    29231770.0    20968810.0  \n",
       "\n",
       "[132 rows x 26 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Преобразование столбца с датой в формат datetime\n",
    "data['<DATE>'] = pd.to_datetime(data['<DATE>'], format='%y%m%d')\n",
    "\n",
    "# Сортировка данных по столбцу с датой\n",
    "data = data.sort_values(by='<DATE>')\n",
    "\n",
    "# Добавление значений за пять дней назад для каждого столбца\n",
    "columns_to_shift = ['<CLOSE>', '<HIGH>', '<LOW>', '<VOL>']\n",
    "for col in columns_to_shift:\n",
    "    for i in range(1, 6):\n",
    "        data[f'{col}_{i}d_ago'] = data[col].shift(i)\n",
    "\n",
    "# Вывод измененного DataFrame\n",
    "data.dropna(inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;_1d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_2d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_3d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_4d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_5d_ago</th>\n",
       "      <th>&lt;HIGH&gt;_1d_ago</th>\n",
       "      <th>&lt;HIGH&gt;_2d_ago</th>\n",
       "      <th>&lt;HIGH&gt;_3d_ago</th>\n",
       "      <th>&lt;HIGH&gt;_4d_ago</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;LOW&gt;_1d_ago</th>\n",
       "      <th>&lt;LOW&gt;_2d_ago</th>\n",
       "      <th>&lt;LOW&gt;_3d_ago</th>\n",
       "      <th>&lt;LOW&gt;_4d_ago</th>\n",
       "      <th>&lt;LOW&gt;_5d_ago</th>\n",
       "      <th>&lt;VOL&gt;_1d_ago</th>\n",
       "      <th>&lt;VOL&gt;_2d_ago</th>\n",
       "      <th>&lt;VOL&gt;_3d_ago</th>\n",
       "      <th>&lt;VOL&gt;_4d_ago</th>\n",
       "      <th>&lt;VOL&gt;_5d_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>238.89</td>\n",
       "      <td>235.77</td>\n",
       "      <td>242.62</td>\n",
       "      <td>239.86</td>\n",
       "      <td>240.66</td>\n",
       "      <td>239.74</td>\n",
       "      <td>242.99</td>\n",
       "      <td>...</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>234.00</td>\n",
       "      <td>237.40</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "      <td>76740930.0</td>\n",
       "      <td>83246880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-05-11</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>238.89</td>\n",
       "      <td>235.77</td>\n",
       "      <td>227.50</td>\n",
       "      <td>239.86</td>\n",
       "      <td>240.66</td>\n",
       "      <td>239.74</td>\n",
       "      <td>...</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>234.00</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "      <td>76740930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-05-12</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>238.89</td>\n",
       "      <td>235.38</td>\n",
       "      <td>227.50</td>\n",
       "      <td>239.86</td>\n",
       "      <td>240.66</td>\n",
       "      <td>...</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>236.05</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "      <td>53006840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-05-15</td>\n",
       "      <td>229.29</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>237.70</td>\n",
       "      <td>232.47</td>\n",
       "      <td>235.38</td>\n",
       "      <td>227.50</td>\n",
       "      <td>239.86</td>\n",
       "      <td>...</td>\n",
       "      <td>226.15</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>237.30</td>\n",
       "      <td>69831820.0</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "      <td>61314710.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-05-16</td>\n",
       "      <td>231.70</td>\n",
       "      <td>229.29</td>\n",
       "      <td>229.32</td>\n",
       "      <td>227.06</td>\n",
       "      <td>238.27</td>\n",
       "      <td>231.75</td>\n",
       "      <td>232.47</td>\n",
       "      <td>235.38</td>\n",
       "      <td>227.50</td>\n",
       "      <td>...</td>\n",
       "      <td>228.52</td>\n",
       "      <td>226.15</td>\n",
       "      <td>223.94</td>\n",
       "      <td>215.70</td>\n",
       "      <td>237.36</td>\n",
       "      <td>48873370.0</td>\n",
       "      <td>69831820.0</td>\n",
       "      <td>197037380.0</td>\n",
       "      <td>154134860.0</td>\n",
       "      <td>47676110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>269.68</td>\n",
       "      <td>268.35</td>\n",
       "      <td>269.89</td>\n",
       "      <td>269.78</td>\n",
       "      <td>270.98</td>\n",
       "      <td>270.30</td>\n",
       "      <td>270.50</td>\n",
       "      <td>...</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>266.87</td>\n",
       "      <td>268.60</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "      <td>26117980.0</td>\n",
       "      <td>33261680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>269.68</td>\n",
       "      <td>268.35</td>\n",
       "      <td>273.87</td>\n",
       "      <td>269.78</td>\n",
       "      <td>270.98</td>\n",
       "      <td>270.30</td>\n",
       "      <td>...</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>266.87</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "      <td>26117980.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2023-11-08</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>269.68</td>\n",
       "      <td>274.78</td>\n",
       "      <td>273.87</td>\n",
       "      <td>269.78</td>\n",
       "      <td>270.98</td>\n",
       "      <td>...</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>267.60</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "      <td>20587810.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>278.15</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>269.06</td>\n",
       "      <td>278.35</td>\n",
       "      <td>274.78</td>\n",
       "      <td>273.87</td>\n",
       "      <td>269.78</td>\n",
       "      <td>...</td>\n",
       "      <td>273.28</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>268.50</td>\n",
       "      <td>58000060.0</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "      <td>25499750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2023-11-10</td>\n",
       "      <td>276.65</td>\n",
       "      <td>278.15</td>\n",
       "      <td>273.31</td>\n",
       "      <td>273.42</td>\n",
       "      <td>268.54</td>\n",
       "      <td>278.85</td>\n",
       "      <td>278.35</td>\n",
       "      <td>274.78</td>\n",
       "      <td>273.87</td>\n",
       "      <td>...</td>\n",
       "      <td>276.02</td>\n",
       "      <td>273.28</td>\n",
       "      <td>272.20</td>\n",
       "      <td>268.62</td>\n",
       "      <td>267.20</td>\n",
       "      <td>28258660.0</td>\n",
       "      <td>58000060.0</td>\n",
       "      <td>32183320.0</td>\n",
       "      <td>29231770.0</td>\n",
       "      <td>20968810.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        <DATE>  <CLOSE>_1d_ago  <CLOSE>_2d_ago  <CLOSE>_3d_ago  \\\n",
       "5   2023-05-10          238.27          237.70          238.89   \n",
       "6   2023-05-11          227.06          238.27          237.70   \n",
       "7   2023-05-12          229.32          227.06          238.27   \n",
       "8   2023-05-15          229.29          229.32          227.06   \n",
       "9   2023-05-16          231.70          229.29          229.32   \n",
       "..         ...             ...             ...             ...   \n",
       "132 2023-11-06          268.54          269.06          269.68   \n",
       "133 2023-11-07          273.42          268.54          269.06   \n",
       "134 2023-11-08          273.31          273.42          268.54   \n",
       "135 2023-11-09          278.15          273.31          273.42   \n",
       "136 2023-11-10          276.65          278.15          273.31   \n",
       "\n",
       "     <CLOSE>_4d_ago  <CLOSE>_5d_ago  <HIGH>_1d_ago  <HIGH>_2d_ago  \\\n",
       "5            235.77          242.62         239.86         240.66   \n",
       "6            238.89          235.77         227.50         239.86   \n",
       "7            237.70          238.89         235.38         227.50   \n",
       "8            238.27          237.70         232.47         235.38   \n",
       "9            227.06          238.27         231.75         232.47   \n",
       "..              ...             ...            ...            ...   \n",
       "132          268.35          269.89         269.78         270.98   \n",
       "133          269.68          268.35         273.87         269.78   \n",
       "134          269.06          269.68         274.78         273.87   \n",
       "135          268.54          269.06         278.35         274.78   \n",
       "136          273.42          268.54         278.85         278.35   \n",
       "\n",
       "     <HIGH>_3d_ago  <HIGH>_4d_ago  ...  <LOW>_1d_ago  <LOW>_2d_ago  \\\n",
       "5           239.74         242.99  ...        237.36        237.30   \n",
       "6           240.66         239.74  ...        215.70        237.36   \n",
       "7           239.86         240.66  ...        223.94        215.70   \n",
       "8           227.50         239.86  ...        226.15        223.94   \n",
       "9           235.38         227.50  ...        228.52        226.15   \n",
       "..             ...            ...  ...           ...           ...   \n",
       "132         270.30         270.50  ...        267.20        268.50   \n",
       "133         270.98         270.30  ...        268.62        267.20   \n",
       "134         269.78         270.98  ...        272.20        268.62   \n",
       "135         273.87         269.78  ...        273.28        272.20   \n",
       "136         274.78         273.87  ...        276.02        273.28   \n",
       "\n",
       "     <LOW>_3d_ago  <LOW>_4d_ago  <LOW>_5d_ago  <VOL>_1d_ago  <VOL>_2d_ago  \\\n",
       "5          236.05        234.00        237.40    47676110.0    61314710.0   \n",
       "6          237.30        236.05        234.00   154134860.0    47676110.0   \n",
       "7          237.36        237.30        236.05   197037380.0   154134860.0   \n",
       "8          215.70        237.36        237.30    69831820.0   197037380.0   \n",
       "9          223.94        215.70        237.36    48873370.0    69831820.0   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "132        267.60        266.87        268.60    20968810.0    25499750.0   \n",
       "133        268.50        267.60        266.87    29231770.0    20968810.0   \n",
       "134        267.20        268.50        267.60    32183320.0    29231770.0   \n",
       "135        268.62        267.20        268.50    58000060.0    32183320.0   \n",
       "136        272.20        268.62        267.20    28258660.0    58000060.0   \n",
       "\n",
       "     <VOL>_3d_ago  <VOL>_4d_ago  <VOL>_5d_ago  \n",
       "5      53006840.0    76740930.0    83246880.0  \n",
       "6      61314710.0    53006840.0    76740930.0  \n",
       "7      47676110.0    61314710.0    53006840.0  \n",
       "8     154134860.0    47676110.0    61314710.0  \n",
       "9     197037380.0   154134860.0    47676110.0  \n",
       "..            ...           ...           ...  \n",
       "132    20587810.0    26117980.0    33261680.0  \n",
       "133    25499750.0    20587810.0    26117980.0  \n",
       "134    20968810.0    25499750.0    20587810.0  \n",
       "135    29231770.0    20968810.0    25499750.0  \n",
       "136    32183320.0    29231770.0    20968810.0  \n",
       "\n",
       "[132 rows x 21 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = torch.tensor(data['<CLOSE>'].values, dtype=torch.float32).view(-1, 1)\n",
    "data.drop(['<CLOSE>','<OPEN>','<HIGH>','<LOW>','<VOL>'],axis=1,inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DATE>              int64\n",
       "<CLOSE>_1d_ago    float64\n",
       "<CLOSE>_2d_ago    float64\n",
       "<CLOSE>_3d_ago    float64\n",
       "<CLOSE>_4d_ago    float64\n",
       "<CLOSE>_5d_ago    float64\n",
       "<HIGH>_1d_ago     float64\n",
       "<HIGH>_2d_ago     float64\n",
       "<HIGH>_3d_ago     float64\n",
       "<HIGH>_4d_ago     float64\n",
       "<HIGH>_5d_ago     float64\n",
       "<LOW>_1d_ago      float64\n",
       "<LOW>_2d_ago      float64\n",
       "<LOW>_3d_ago      float64\n",
       "<LOW>_4d_ago      float64\n",
       "<LOW>_5d_ago      float64\n",
       "<VOL>_1d_ago      float64\n",
       "<VOL>_2d_ago      float64\n",
       "<VOL>_3d_ago      float64\n",
       "<VOL>_4d_ago      float64\n",
       "<VOL>_5d_ago      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['<DATE>'] = pd.to_datetime(data['<DATE>']).astype(np.int64)\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.6836768e+18, 2.3827000e+02, 2.3770000e+02, ..., 5.3006840e+07,\n",
       "        7.6740928e+07, 8.3246880e+07],\n",
       "       [1.6837632e+18, 2.2706000e+02, 2.3827000e+02, ..., 6.1314712e+07,\n",
       "        5.3006840e+07, 7.6740928e+07],\n",
       "       [1.6838496e+18, 2.2932001e+02, 2.2706000e+02, ..., 4.7676112e+07,\n",
       "        6.1314712e+07, 5.3006840e+07],\n",
       "       ...,\n",
       "       [1.6994016e+18, 2.7331000e+02, 2.7342001e+02, ..., 2.0968810e+07,\n",
       "        2.5499750e+07, 2.0587810e+07],\n",
       "       [1.6994880e+18, 2.7814999e+02, 2.7331000e+02, ..., 2.9231770e+07,\n",
       "        2.0968810e+07, 2.5499750e+07],\n",
       "       [1.6995744e+18, 2.7664999e+02, 2.7814999e+02, ..., 3.2183320e+07,\n",
       "        2.9231770e+07, 2.0968810e+07]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = data.values.astype('float32')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 21)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[ 0.2084],\n",
      "        [-0.1012],\n",
      "        [-0.0546],\n",
      "        [-0.0318],\n",
      "        [-0.0913]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[-0.0906],\n",
      "        [ 0.0638],\n",
      "        [-0.1381],\n",
      "        [ 0.2547],\n",
      "        [ 0.2273]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[ 0.0237],\n",
      "        [ 0.0747],\n",
      "        [-0.0482],\n",
      "        [ 0.1888],\n",
      "        [ 0.0410]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[ 0.2221],\n",
      "        [ 0.3242],\n",
      "        [ 0.0673],\n",
      "        [-0.1171],\n",
      "        [ 0.0076]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[-0.0402],\n",
      "        [ 0.3008],\n",
      "        [ 0.1218],\n",
      "        [-0.1165],\n",
      "        [ 0.0282]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[0.2100],\n",
      "        [0.1419],\n",
      "        [0.2577],\n",
      "        [0.1570],\n",
      "        [0.1713]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[0.3547],\n",
      "        [0.0415],\n",
      "        [0.2696],\n",
      "        [0.1072],\n",
      "        [0.2220]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[ 0.1203],\n",
      "        [-0.1255],\n",
      "        [ 0.1008],\n",
      "        [ 0.0832],\n",
      "        [-0.0571]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[ 0.2951],\n",
      "        [ 0.0700],\n",
      "        [ 0.3105],\n",
      "        [ 0.2259],\n",
      "        [-0.0687]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[0.0675],\n",
      "        [0.1235],\n",
      "        [0.1751],\n",
      "        [0.1707],\n",
      "        [0.0011]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[0.3146],\n",
      "        [0.3580],\n",
      "        [0.4256],\n",
      "        [0.1717],\n",
      "        [0.2784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[0.0009],\n",
      "        [0.2487],\n",
      "        [0.2563],\n",
      "        [0.2177],\n",
      "        [0.2146]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[0.2167],\n",
      "        [0.2224],\n",
      "        [0.4161],\n",
      "        [0.1240],\n",
      "        [0.0568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[0.1282],\n",
      "        [0.3038],\n",
      "        [0.0011],\n",
      "        [0.3849],\n",
      "        [0.1564]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[-0.0227],\n",
      "        [ 0.2163],\n",
      "        [ 0.3431],\n",
      "        [ 0.2014],\n",
      "        [ 0.1285]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[0.1397],\n",
      "        [0.2841],\n",
      "        [0.2673],\n",
      "        [0.3051],\n",
      "        [0.2174]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[0.2504],\n",
      "        [0.2503],\n",
      "        [0.1318],\n",
      "        [0.1333],\n",
      "        [0.3482]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[0.1729],\n",
      "        [0.3075],\n",
      "        [0.2924],\n",
      "        [0.2864],\n",
      "        [0.0270]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[0.3189],\n",
      "        [0.2124],\n",
      "        [0.0909],\n",
      "        [0.3550],\n",
      "        [0.4689]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[0.2031],\n",
      "        [0.3370],\n",
      "        [0.3880],\n",
      "        [0.4265],\n",
      "        [0.3719]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[0.2798],\n",
      "        [0.5144],\n",
      "        [0.4916],\n",
      "        [0.4131],\n",
      "        [0.2958]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/10000], Loss: 66068.8516\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[191.7423],\n",
      "        [246.7381],\n",
      "        [248.5055],\n",
      "        [280.3277],\n",
      "        [262.8433]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[202.0995],\n",
      "        [236.8486],\n",
      "        [218.2236],\n",
      "        [247.1108],\n",
      "        [279.8350]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[206.2508],\n",
      "        [224.9613],\n",
      "        [252.7348],\n",
      "        [249.1004],\n",
      "        [232.2039]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[143.6990],\n",
      "        [212.1008],\n",
      "        [234.6123],\n",
      "        [209.6897],\n",
      "        [247.5637]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[165.5647],\n",
      "        [213.0339],\n",
      "        [224.1021],\n",
      "        [208.5359],\n",
      "        [174.9317]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[160.6192],\n",
      "        [235.8774],\n",
      "        [217.0352],\n",
      "        [208.3018],\n",
      "        [191.3726]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[187.6877],\n",
      "        [207.6497],\n",
      "        [258.7867],\n",
      "        [247.4996],\n",
      "        [252.8785]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[225.6256],\n",
      "        [209.6885],\n",
      "        [247.9636],\n",
      "        [283.0493],\n",
      "        [276.3102]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[203.2573],\n",
      "        [220.1443],\n",
      "        [197.8654],\n",
      "        [209.4866],\n",
      "        [187.4693]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[230.9755],\n",
      "        [259.1380],\n",
      "        [261.8425],\n",
      "        [232.1960],\n",
      "        [244.7515]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[168.7563],\n",
      "        [179.0969],\n",
      "        [ 97.0303],\n",
      "        [187.3397],\n",
      "        [230.0550]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[110.4877],\n",
      "        [238.2402],\n",
      "        [253.3959],\n",
      "        [293.2117],\n",
      "        [223.5695]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[206.8015],\n",
      "        [236.9680],\n",
      "        [247.1712],\n",
      "        [228.9214],\n",
      "        [261.9153]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[230.6000],\n",
      "        [173.2394],\n",
      "        [217.9885],\n",
      "        [193.8805],\n",
      "        [239.9896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[190.9892],\n",
      "        [200.8845],\n",
      "        [245.2946],\n",
      "        [286.3279],\n",
      "        [295.1622]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[171.9557],\n",
      "        [234.1519],\n",
      "        [184.6964],\n",
      "        [270.2228],\n",
      "        [248.3337]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[201.2837],\n",
      "        [208.2098],\n",
      "        [236.4762],\n",
      "        [279.1509],\n",
      "        [262.8662]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[222.9962],\n",
      "        [225.4419],\n",
      "        [222.4021],\n",
      "        [209.7331],\n",
      "        [241.8030]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[206.9698],\n",
      "        [208.2319],\n",
      "        [207.6365],\n",
      "        [206.7360],\n",
      "        [268.0784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[165.8934],\n",
      "        [219.3188],\n",
      "        [233.2583],\n",
      "        [236.6529],\n",
      "        [249.2374]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[226.9706],\n",
      "        [189.8263],\n",
      "        [264.6545],\n",
      "        [233.7087],\n",
      "        [302.6296]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1001/10000], Loss: 1892.0726\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[213.6191],\n",
      "        [254.0799],\n",
      "        [266.4980],\n",
      "        [281.2918],\n",
      "        [281.1472]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[219.0943],\n",
      "        [268.5200],\n",
      "        [247.9297],\n",
      "        [243.6835],\n",
      "        [277.6566]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[218.0716],\n",
      "        [238.9842],\n",
      "        [258.7522],\n",
      "        [270.2497],\n",
      "        [249.2751]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[196.1564],\n",
      "        [244.9580],\n",
      "        [273.0717],\n",
      "        [239.4807],\n",
      "        [258.1464]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[201.8954],\n",
      "        [240.0878],\n",
      "        [256.1256],\n",
      "        [252.9357],\n",
      "        [221.2214]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[216.0051],\n",
      "        [268.8536],\n",
      "        [251.1031],\n",
      "        [247.1933],\n",
      "        [244.4759]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[216.2863],\n",
      "        [246.3536],\n",
      "        [258.9379],\n",
      "        [250.9234],\n",
      "        [272.0297]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[237.1055],\n",
      "        [242.3172],\n",
      "        [259.3046],\n",
      "        [287.8169],\n",
      "        [279.7870]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[216.5281],\n",
      "        [255.5332],\n",
      "        [240.8045],\n",
      "        [256.9652],\n",
      "        [231.7760]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[251.8307],\n",
      "        [274.3785],\n",
      "        [273.4965],\n",
      "        [242.1400],\n",
      "        [259.9207]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[232.6116],\n",
      "        [243.3505],\n",
      "        [157.8112],\n",
      "        [244.9159],\n",
      "        [261.3477]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[144.4574],\n",
      "        [257.4830],\n",
      "        [263.2826],\n",
      "        [299.2711],\n",
      "        [237.6427]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[250.3310],\n",
      "        [270.3896],\n",
      "        [270.5498],\n",
      "        [260.8258],\n",
      "        [269.7294]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[261.1083],\n",
      "        [217.7599],\n",
      "        [229.5175],\n",
      "        [250.7234],\n",
      "        [289.6646]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[215.1689],\n",
      "        [248.6153],\n",
      "        [257.4974],\n",
      "        [292.5566],\n",
      "        [287.8509]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[220.8878],\n",
      "        [245.9319],\n",
      "        [225.3779],\n",
      "        [291.4195],\n",
      "        [279.8784]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[236.6906],\n",
      "        [250.1628],\n",
      "        [263.3262],\n",
      "        [279.3423],\n",
      "        [286.9814]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[237.4076],\n",
      "        [230.2911],\n",
      "        [246.3052],\n",
      "        [262.0854],\n",
      "        [278.9780]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[240.4783],\n",
      "        [251.6526],\n",
      "        [248.8358],\n",
      "        [251.8354],\n",
      "        [292.5403]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[212.6243],\n",
      "        [248.4917],\n",
      "        [258.8921],\n",
      "        [241.8359],\n",
      "        [260.3474]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[252.5364],\n",
      "        [233.7304],\n",
      "        [275.7144],\n",
      "        [260.2613],\n",
      "        [291.0833]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [2001/10000], Loss: 584.7346\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[222.0918],\n",
      "        [248.3326],\n",
      "        [259.4339],\n",
      "        [269.2816],\n",
      "        [272.7487]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[221.7537],\n",
      "        [262.4082],\n",
      "        [254.3548],\n",
      "        [232.0716],\n",
      "        [259.7046]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[211.4851],\n",
      "        [237.9807],\n",
      "        [251.3885],\n",
      "        [265.6969],\n",
      "        [248.6550]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[220.5072],\n",
      "        [253.8059],\n",
      "        [279.6134],\n",
      "        [243.7738],\n",
      "        [254.0717]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[220.6261],\n",
      "        [245.4543],\n",
      "        [254.4953],\n",
      "        [264.5283],\n",
      "        [238.4236]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[233.7125],\n",
      "        [273.8452],\n",
      "        [256.0863],\n",
      "        [255.1458],\n",
      "        [251.1097]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[230.6744],\n",
      "        [256.0812],\n",
      "        [244.8341],\n",
      "        [235.3807],\n",
      "        [270.5861]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[228.2888],\n",
      "        [254.1494],\n",
      "        [252.9179],\n",
      "        [273.9711],\n",
      "        [260.9616]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[215.8349],\n",
      "        [255.8786],\n",
      "        [241.5887],\n",
      "        [270.5881],\n",
      "        [242.8095]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[251.4887],\n",
      "        [267.1894],\n",
      "        [266.9838],\n",
      "        [235.2573],\n",
      "        [251.5672]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[258.0780],\n",
      "        [266.4204],\n",
      "        [189.7966],\n",
      "        [260.0080],\n",
      "        [261.0679]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[171.1723],\n",
      "        [256.2832],\n",
      "        [255.5995],\n",
      "        [288.7344],\n",
      "        [231.4922]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[260.5317],\n",
      "        [271.0375],\n",
      "        [268.8199],\n",
      "        [263.9580],\n",
      "        [260.7765]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[261.6465],\n",
      "        [230.9416],\n",
      "        [229.5549],\n",
      "        [268.8250],\n",
      "        [295.5840]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[223.1207],\n",
      "        [262.5571],\n",
      "        [256.5094],\n",
      "        [277.0189],\n",
      "        [265.5544]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[237.0199],\n",
      "        [245.6593],\n",
      "        [236.7606],\n",
      "        [285.2094],\n",
      "        [271.3483]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[239.7043],\n",
      "        [257.3513],\n",
      "        [257.3526],\n",
      "        [261.2837],\n",
      "        [281.8744]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[234.1895],\n",
      "        [223.1918],\n",
      "        [237.6782],\n",
      "        [277.8820],\n",
      "        [280.7404]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[252.5746],\n",
      "        [261.4370],\n",
      "        [263.6880],\n",
      "        [261.5293],\n",
      "        [292.0364]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[229.8820],\n",
      "        [255.8869],\n",
      "        [271.6956],\n",
      "        [233.4796],\n",
      "        [257.6905]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[252.6122],\n",
      "        [246.5685],\n",
      "        [267.0374],\n",
      "        [262.1053],\n",
      "        [264.7321]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [3001/10000], Loss: 176.7830\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[229.2930],\n",
      "        [247.9052],\n",
      "        [255.8950],\n",
      "        [266.4003],\n",
      "        [270.0498]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[225.6195],\n",
      "        [254.1813],\n",
      "        [257.4710],\n",
      "        [232.3952],\n",
      "        [252.5456]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[210.5936],\n",
      "        [242.6882],\n",
      "        [254.4680],\n",
      "        [257.7422],\n",
      "        [246.2955]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[231.8005],\n",
      "        [259.7050],\n",
      "        [280.1648],\n",
      "        [246.7292],\n",
      "        [253.8457]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[231.9528],\n",
      "        [250.2078],\n",
      "        [250.1157],\n",
      "        [268.5933],\n",
      "        [245.6917]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[237.3152],\n",
      "        [275.9875],\n",
      "        [253.3522],\n",
      "        [255.1486],\n",
      "        [248.5024]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[241.5366],\n",
      "        [258.8386],\n",
      "        [240.5408],\n",
      "        [228.6406],\n",
      "        [269.1913]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[224.8443],\n",
      "        [261.6960],\n",
      "        [249.9689],\n",
      "        [266.8406],\n",
      "        [252.1645]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[220.2097],\n",
      "        [252.5129],\n",
      "        [238.6810],\n",
      "        [274.7993],\n",
      "        [243.7797]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[252.3477],\n",
      "        [264.7462],\n",
      "        [262.6615],\n",
      "        [234.0354],\n",
      "        [247.9346]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[263.5879],\n",
      "        [272.5349],\n",
      "        [202.7012],\n",
      "        [260.6245],\n",
      "        [259.2982]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[191.2593],\n",
      "        [257.2595],\n",
      "        [254.7433],\n",
      "        [285.6342],\n",
      "        [231.1166]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[261.7926],\n",
      "        [267.8909],\n",
      "        [267.6106],\n",
      "        [263.2684],\n",
      "        [257.1672]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[260.5356],\n",
      "        [236.5553],\n",
      "        [236.1154],\n",
      "        [271.9312],\n",
      "        [292.3516]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[229.0013],\n",
      "        [265.9773],\n",
      "        [261.2634],\n",
      "        [271.5163],\n",
      "        [257.4926]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[244.4311],\n",
      "        [252.8062],\n",
      "        [242.4471],\n",
      "        [278.9897],\n",
      "        [263.9399]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[239.0753],\n",
      "        [259.5126],\n",
      "        [252.7148],\n",
      "        [254.6914],\n",
      "        [276.3596]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[233.8736],\n",
      "        [226.0922],\n",
      "        [229.0346],\n",
      "        [281.4235],\n",
      "        [278.6151]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[259.6662],\n",
      "        [262.0058],\n",
      "        [269.5164],\n",
      "        [261.8999],\n",
      "        [291.2481]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[235.5672],\n",
      "        [261.7791],\n",
      "        [282.7641],\n",
      "        [232.9324],\n",
      "        [257.3209]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[251.3410],\n",
      "        [251.8189],\n",
      "        [264.8902],\n",
      "        [263.6370],\n",
      "        [254.4563]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [4001/10000], Loss: 134.0927\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[233.0440],\n",
      "        [248.0310],\n",
      "        [254.3216],\n",
      "        [265.3004],\n",
      "        [269.7738]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[228.5331],\n",
      "        [248.8072],\n",
      "        [258.2388],\n",
      "        [234.8914],\n",
      "        [248.8359]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[212.0858],\n",
      "        [246.4922],\n",
      "        [258.0016],\n",
      "        [251.1388],\n",
      "        [244.2827]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[238.2103],\n",
      "        [262.5314],\n",
      "        [279.5726],\n",
      "        [249.3019],\n",
      "        [254.2798]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[238.8485],\n",
      "        [253.6847],\n",
      "        [247.4052],\n",
      "        [269.6556],\n",
      "        [249.7570]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[238.5719],\n",
      "        [276.2354],\n",
      "        [249.4628],\n",
      "        [254.0318],\n",
      "        [246.2195]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[247.3931],\n",
      "        [258.6752],\n",
      "        [238.7728],\n",
      "        [225.9638],\n",
      "        [267.2971]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[223.7247],\n",
      "        [265.6020],\n",
      "        [248.5023],\n",
      "        [262.8147],\n",
      "        [247.8013]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[224.4856],\n",
      "        [250.8983],\n",
      "        [238.4671],\n",
      "        [275.8193],\n",
      "        [242.8524]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[253.4731],\n",
      "        [263.1254],\n",
      "        [259.3863],\n",
      "        [235.2136],\n",
      "        [247.7496]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[262.8985],\n",
      "        [274.4292],\n",
      "        [208.6923],\n",
      "        [258.8355],\n",
      "        [258.9997]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[205.9203],\n",
      "        [257.5486],\n",
      "        [254.9782],\n",
      "        [283.9162],\n",
      "        [232.4196]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[260.8616],\n",
      "        [265.7437],\n",
      "        [265.9054],\n",
      "        [261.9677],\n",
      "        [256.0877]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[258.9787],\n",
      "        [240.3166],\n",
      "        [242.0167],\n",
      "        [271.3659],\n",
      "        [288.4163]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[232.5895],\n",
      "        [266.6492],\n",
      "        [264.9333],\n",
      "        [268.4078],\n",
      "        [254.2383]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[249.9114],\n",
      "        [259.9802],\n",
      "        [247.2000],\n",
      "        [274.2131],\n",
      "        [260.8030]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[238.7637],\n",
      "        [261.2408],\n",
      "        [251.8054],\n",
      "        [252.4491],\n",
      "        [272.2796]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[234.5433],\n",
      "        [230.7114],\n",
      "        [224.0861],\n",
      "        [280.3131],\n",
      "        [275.6457]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[262.9825],\n",
      "        [259.9379],\n",
      "        [270.3997],\n",
      "        [260.3987],\n",
      "        [288.8508]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[237.5934],\n",
      "        [264.7658],\n",
      "        [289.6451],\n",
      "        [234.3322],\n",
      "        [256.8920]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[249.5825],\n",
      "        [254.0883],\n",
      "        [263.9567],\n",
      "        [264.0766],\n",
      "        [250.1303]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [5001/10000], Loss: 137.5769\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[234.9465],\n",
      "        [248.0984],\n",
      "        [253.4348],\n",
      "        [264.2401],\n",
      "        [270.0060]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[230.5358],\n",
      "        [245.6591],\n",
      "        [258.2115],\n",
      "        [237.2141],\n",
      "        [246.6746]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[214.4303],\n",
      "        [248.8338],\n",
      "        [259.6934],\n",
      "        [247.0577],\n",
      "        [243.6667]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[242.3591],\n",
      "        [263.6633],\n",
      "        [279.0438],\n",
      "        [251.6060],\n",
      "        [254.9964]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[243.6077],\n",
      "        [256.3474],\n",
      "        [245.7212],\n",
      "        [269.3640],\n",
      "        [252.5865]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[239.4958],\n",
      "        [275.5311],\n",
      "        [246.8553],\n",
      "        [253.1079],\n",
      "        [244.6850]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[250.2622],\n",
      "        [257.8299],\n",
      "        [237.8651],\n",
      "        [225.2183],\n",
      "        [265.7018]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[223.7534],\n",
      "        [267.7971],\n",
      "        [247.8761],\n",
      "        [260.4903],\n",
      "        [245.0947]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[227.3651],\n",
      "        [250.2762],\n",
      "        [240.0811],\n",
      "        [275.7713],\n",
      "        [242.0994]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[254.3726],\n",
      "        [261.6745],\n",
      "        [257.0901],\n",
      "        [237.1895],\n",
      "        [248.8111]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[261.0580],\n",
      "        [275.3188],\n",
      "        [212.0452],\n",
      "        [257.6852],\n",
      "        [259.1273]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[217.0489],\n",
      "        [257.3354],\n",
      "        [255.2308],\n",
      "        [282.2114],\n",
      "        [234.0555]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[259.6911],\n",
      "        [264.5000],\n",
      "        [264.2384],\n",
      "        [261.2272],\n",
      "        [256.1949]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[257.4269],\n",
      "        [243.3326],\n",
      "        [246.2266],\n",
      "        [270.2242],\n",
      "        [285.0176]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[234.8465],\n",
      "        [266.5381],\n",
      "        [267.0308],\n",
      "        [265.8708],\n",
      "        [252.4097]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[254.0261],\n",
      "        [265.1985],\n",
      "        [251.1117],\n",
      "        [271.0589],\n",
      "        [259.6221]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[238.4746],\n",
      "        [262.2834],\n",
      "        [252.4604],\n",
      "        [251.1580],\n",
      "        [269.4895]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[235.4082],\n",
      "        [234.8598],\n",
      "        [221.2996],\n",
      "        [278.1935],\n",
      "        [272.7253]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[264.5358],\n",
      "        [257.9084],\n",
      "        [269.4604],\n",
      "        [259.4225],\n",
      "        [285.7289]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[238.6788],\n",
      "        [265.8358],\n",
      "        [293.4593],\n",
      "        [236.0512],\n",
      "        [256.5820]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[248.1767],\n",
      "        [255.3073],\n",
      "        [263.1131],\n",
      "        [263.7760],\n",
      "        [247.7520]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [6001/10000], Loss: 143.0507\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[236.0072],\n",
      "        [248.0636],\n",
      "        [252.7670],\n",
      "        [262.9817],\n",
      "        [270.2828]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[231.9131],\n",
      "        [243.9124],\n",
      "        [257.9823],\n",
      "        [239.0648],\n",
      "        [245.2955]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[217.0516],\n",
      "        [250.2723],\n",
      "        [260.1434],\n",
      "        [244.6424],\n",
      "        [243.8223]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[245.1716],\n",
      "        [264.0074],\n",
      "        [278.5917],\n",
      "        [253.5317],\n",
      "        [255.7040]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[247.0535],\n",
      "        [258.5108],\n",
      "        [244.5018],\n",
      "        [268.4958],\n",
      "        [254.5963]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[240.2219],\n",
      "        [274.5256],\n",
      "        [245.5468],\n",
      "        [252.3931],\n",
      "        [243.4924]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[251.5669],\n",
      "        [256.9908],\n",
      "        [237.4311],\n",
      "        [225.4077],\n",
      "        [264.4660]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[224.4560],\n",
      "        [269.1711],\n",
      "        [247.6164],\n",
      "        [259.0556],\n",
      "        [243.1290]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[229.2004],\n",
      "        [249.9838],\n",
      "        [242.4295],\n",
      "        [275.3898],\n",
      "        [241.7241]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[254.9595],\n",
      "        [260.5610],\n",
      "        [255.4806],\n",
      "        [239.2488],\n",
      "        [250.0641]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[259.3902],\n",
      "        [275.8464],\n",
      "        [214.0758],\n",
      "        [257.2480],\n",
      "        [259.1794]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[225.5355],\n",
      "        [257.0914],\n",
      "        [255.4912],\n",
      "        [280.3551],\n",
      "        [235.7261]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[258.6294],\n",
      "        [263.6217],\n",
      "        [262.9163],\n",
      "        [260.9471],\n",
      "        [256.6548]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[256.2264],\n",
      "        [245.8162],\n",
      "        [249.2214],\n",
      "        [269.1784],\n",
      "        [282.3474]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[236.3367],\n",
      "        [266.1044],\n",
      "        [268.1938],\n",
      "        [263.8835],\n",
      "        [251.3065]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[256.9370],\n",
      "        [268.6635],\n",
      "        [254.0253],\n",
      "        [269.1361],\n",
      "        [259.1313]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[238.1233],\n",
      "        [262.7099],\n",
      "        [253.6423],\n",
      "        [250.1446],\n",
      "        [267.5520]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[236.1908],\n",
      "        [238.3198],\n",
      "        [219.5312],\n",
      "        [276.1579],\n",
      "        [270.1943]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[265.2682],\n",
      "        [256.4167],\n",
      "        [268.1533],\n",
      "        [259.1567],\n",
      "        [282.4969]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[239.5802],\n",
      "        [265.9550],\n",
      "        [295.2966],\n",
      "        [237.6764],\n",
      "        [256.3162]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[247.2264],\n",
      "        [256.1743],\n",
      "        [262.3344],\n",
      "        [263.1502],\n",
      "        [246.3125]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [7001/10000], Loss: 145.8158\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[236.6729],\n",
      "        [247.9984],\n",
      "        [252.1872],\n",
      "        [261.6617],\n",
      "        [270.4821]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[232.9149],\n",
      "        [242.9513],\n",
      "        [257.6991],\n",
      "        [240.4846],\n",
      "        [244.2639]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[219.6541],\n",
      "        [251.1888],\n",
      "        [260.0001],\n",
      "        [243.0994],\n",
      "        [244.1965]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[247.1656],\n",
      "        [264.0069],\n",
      "        [278.1402],\n",
      "        [255.0689],\n",
      "        [256.3045]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[249.5241],\n",
      "        [260.2875],\n",
      "        [243.5494],\n",
      "        [267.4269],\n",
      "        [255.9769]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[240.7763],\n",
      "        [273.4592],\n",
      "        [245.0564],\n",
      "        [251.8607],\n",
      "        [242.4416]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[252.1085],\n",
      "        [256.3369],\n",
      "        [237.2698],\n",
      "        [226.0057],\n",
      "        [263.5422]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[225.5161],\n",
      "        [269.9942],\n",
      "        [247.5587],\n",
      "        [258.1262],\n",
      "        [241.5697]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[230.4200],\n",
      "        [249.7724],\n",
      "        [244.8477],\n",
      "        [274.9308],\n",
      "        [241.6056]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[255.3329],\n",
      "        [259.7794],\n",
      "        [254.3832],\n",
      "        [241.1412],\n",
      "        [251.1665]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[258.1307],\n",
      "        [276.2001],\n",
      "        [215.3844],\n",
      "        [257.1761],\n",
      "        [259.0996]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[231.9178],\n",
      "        [256.9312],\n",
      "        [255.7614],\n",
      "        [278.4847],\n",
      "        [237.3211]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[257.7518],\n",
      "        [262.8993],\n",
      "        [261.9470],\n",
      "        [260.9156],\n",
      "        [257.1792]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[255.4575],\n",
      "        [247.8894],\n",
      "        [251.3899],\n",
      "        [268.3339],\n",
      "        [280.3299]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[237.4024],\n",
      "        [265.5311],\n",
      "        [268.8484],\n",
      "        [262.4120],\n",
      "        [250.6776]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[258.9227],\n",
      "        [270.9076],\n",
      "        [256.0816],\n",
      "        [268.0495],\n",
      "        [258.7963]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[237.7776],\n",
      "        [262.7831],\n",
      "        [254.9875],\n",
      "        [249.3018],\n",
      "        [266.1527]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[236.8690],\n",
      "        [241.1724],\n",
      "        [218.2945],\n",
      "        [274.4797],\n",
      "        [268.1236]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[265.6230],\n",
      "        [255.3965],\n",
      "        [267.0680],\n",
      "        [259.2849],\n",
      "        [279.4426]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[240.4510],\n",
      "        [265.6479],\n",
      "        [296.0103],\n",
      "        [239.0797],\n",
      "        [256.0979]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[246.6556],\n",
      "        [256.8579],\n",
      "        [261.6533],\n",
      "        [262.4373],\n",
      "        [245.4508]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [8001/10000], Loss: 146.0313\n",
      "tensor([[250.1600],\n",
      "        [251.9900],\n",
      "        [227.0600],\n",
      "        [248.1000],\n",
      "        [268.5400]])\n",
      "res: tensor([[237.1362],\n",
      "        [247.9579],\n",
      "        [251.6576],\n",
      "        [260.4091],\n",
      "        [270.5777]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[258.5000],\n",
      "        [244.6000],\n",
      "        [264.8500],\n",
      "        [267.9000],\n",
      "        [244.1300]])\n",
      "res: tensor([[233.7029],\n",
      "        [242.4163],\n",
      "        [257.4251],\n",
      "        [241.5513],\n",
      "        [243.4581]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[246.1700],\n",
      "        [265.6800],\n",
      "        [260.4200],\n",
      "        [240.4000],\n",
      "        [246.1900]])\n",
      "res: tensor([[222.0772],\n",
      "        [251.7951],\n",
      "        [259.6299],\n",
      "        [242.0547],\n",
      "        [244.6087]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[266.2300],\n",
      "        [258.1800],\n",
      "        [240.6600],\n",
      "        [269.8900],\n",
      "        [258.7900]])\n",
      "res: tensor([[248.6630],\n",
      "        [263.8827],\n",
      "        [277.6526],\n",
      "        [256.2726],\n",
      "        [256.7942]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[236.4300],\n",
      "        [241.2100],\n",
      "        [260.4500],\n",
      "        [245.1800],\n",
      "        [257.6700]])\n",
      "res: tensor([[251.2308],\n",
      "        [261.7343],\n",
      "        [242.8011],\n",
      "        [266.3533],\n",
      "        [256.8843]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7400],\n",
      "        [253.7700],\n",
      "        [252.7200],\n",
      "        [247.2000],\n",
      "        [230.5500]])\n",
      "res: tensor([[241.2211],\n",
      "        [272.4210],\n",
      "        [244.9884],\n",
      "        [251.4946],\n",
      "        [241.4755]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[256.0200],\n",
      "        [273.7300],\n",
      "        [240.9500],\n",
      "        [245.8500],\n",
      "        [239.9900]])\n",
      "res: tensor([[252.3016],\n",
      "        [255.8867],\n",
      "        [237.2384],\n",
      "        [226.7257],\n",
      "        [262.8658]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.6600],\n",
      "        [266.9300],\n",
      "        [239.6700],\n",
      "        [268.3500],\n",
      "        [231.2700]])\n",
      "res: tensor([[226.7114],\n",
      "        [270.3605],\n",
      "        [247.6405],\n",
      "        [257.4926],\n",
      "        [240.2711]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[247.9900],\n",
      "        [261.4500],\n",
      "        [259.3800],\n",
      "        [263.5100],\n",
      "        [231.0000]])\n",
      "res: tensor([[231.2885],\n",
      "        [249.5551],\n",
      "        [246.9974],\n",
      "        [274.4681],\n",
      "        [241.6098]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[251.1800],\n",
      "        [276.6500],\n",
      "        [231.7000],\n",
      "        [243.9500],\n",
      "        [240.7000]])\n",
      "res: tensor([[255.5821],\n",
      "        [259.2374],\n",
      "        [253.6692],\n",
      "        [242.7906],\n",
      "        [252.0581]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1500],\n",
      "        [269.6800],\n",
      "        [231.7000],\n",
      "        [263.5000],\n",
      "        [270.0000]])\n",
      "res: tensor([[257.2419],\n",
      "        [276.4696],\n",
      "        [216.3043],\n",
      "        [257.2527],\n",
      "        [258.9400]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[259.5300],\n",
      "        [247.0500],\n",
      "        [242.7000],\n",
      "        [260.2100],\n",
      "        [246.4500]])\n",
      "res: tensor([[236.6413],\n",
      "        [256.8367],\n",
      "        [256.0098],\n",
      "        [276.7154],\n",
      "        [238.7874]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[252.6500],\n",
      "        [264.1200],\n",
      "        [278.1500],\n",
      "        [264.7000],\n",
      "        [268.6500]])\n",
      "res: tensor([[257.0695],\n",
      "        [262.2806],\n",
      "        [261.2464],\n",
      "        [260.9884],\n",
      "        [257.6790]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[260.8300],\n",
      "        [243.6700],\n",
      "        [268.5000],\n",
      "        [260.0000],\n",
      "        [246.7700]])\n",
      "res: tensor([[255.0649],\n",
      "        [249.6586],\n",
      "        [252.9971],\n",
      "        [267.6540],\n",
      "        [278.8099]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[262.4000],\n",
      "        [268.1500],\n",
      "        [267.4000],\n",
      "        [259.6300],\n",
      "        [238.4000]])\n",
      "res: tensor([[238.2425],\n",
      "        [264.9131],\n",
      "        [269.2037],\n",
      "        [261.3454],\n",
      "        [250.3467]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.0600],\n",
      "        [268.5700],\n",
      "        [264.6200],\n",
      "        [264.5000],\n",
      "        [243.3300]])\n",
      "res: tensor([[260.2606],\n",
      "        [272.3564],\n",
      "        [257.5086],\n",
      "        [267.4157],\n",
      "        [258.4658]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[242.2000],\n",
      "        [265.2500],\n",
      "        [271.2700],\n",
      "        [229.3200],\n",
      "        [244.8700]])\n",
      "res: tensor([[237.4907],\n",
      "        [262.7023],\n",
      "        [256.3411],\n",
      "        [248.5928],\n",
      "        [265.0834]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[241.7700],\n",
      "        [229.2900],\n",
      "        [244.3300],\n",
      "        [259.6500],\n",
      "        [256.1000]])\n",
      "res: tensor([[237.4615],\n",
      "        [243.5165],\n",
      "        [217.4033],\n",
      "        [273.1874],\n",
      "        [266.4886]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[269.8000],\n",
      "        [256.2500],\n",
      "        [269.9000],\n",
      "        [256.4000],\n",
      "        [255.6800]])\n",
      "res: tensor([[265.8141],\n",
      "        [254.7074],\n",
      "        [266.2895],\n",
      "        [259.5769],\n",
      "        [276.6850]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[267.3900],\n",
      "        [269.7000],\n",
      "        [280.1900],\n",
      "        [241.2500],\n",
      "        [269.1100]])\n",
      "res: tensor([[241.2918],\n",
      "        [265.1786],\n",
      "        [296.1310],\n",
      "        [240.2235],\n",
      "        [255.9408]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[261.1400],\n",
      "        [262.9300],\n",
      "        [244.6500],\n",
      "        [259.0700],\n",
      "        [258.9800]])\n",
      "res: tensor([[246.3691],\n",
      "        [257.4135],\n",
      "        [261.0688],\n",
      "        [261.7523],\n",
      "        [244.9592]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [9001/10000], Loss: 144.3934\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the LSTM model architecture\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions\n",
    "\n",
    "# Set up the model\n",
    "input_size = 21  # Assuming 21 features/columns in your data\n",
    "hidden_size = 64  # Number of LSTM units\n",
    "output_size = 1  # Single output for predicting <CLOSE>\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'data' contains your entire dataset\n",
    "# Split data into features (X) and target variable (y)\n",
    "X = data[:, 1:]  # Exclude the timestamp column if it's the first column\n",
    "y = target_data\n",
    "\n",
    "# Split data into training and testing sets (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert training and testing data to PyTorch tensors\n",
    "train_input = torch.tensor(X_train, dtype=torch.float32)\n",
    "train_target = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "test_input = torch.tensor(X_test, dtype=torch.float32)\n",
    "test_target = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "num_epochs = 10000\n",
    "batch_size = 5  # Batch size of 5\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, len(train_input), batch_size):\n",
    "        # Create batches\n",
    "        input_batch = train_input[i:i+batch_size]\n",
    "        target_batch = train_target[i:i+batch_size]\n",
    "        # Forward pass\n",
    "        outputs = model(input_batch)\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            print(target_batch)\n",
    "            print(\"res:\",outputs)\n",
    "        loss = criterion(outputs, target_batch)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print training statistics\n",
    "    if epoch % 1000 == 0:  # Print every 1000 epochs, adjust as needed\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Training finished')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;VOL&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231108</td>\n",
       "      <td>273.53</td>\n",
       "      <td>278.35</td>\n",
       "      <td>273.28</td>\n",
       "      <td>278.15</td>\n",
       "      <td>58000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231109</td>\n",
       "      <td>278.60</td>\n",
       "      <td>278.85</td>\n",
       "      <td>276.02</td>\n",
       "      <td>276.65</td>\n",
       "      <td>28258660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231110</td>\n",
       "      <td>276.99</td>\n",
       "      <td>281.30</td>\n",
       "      <td>276.60</td>\n",
       "      <td>280.19</td>\n",
       "      <td>44600220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231113</td>\n",
       "      <td>280.40</td>\n",
       "      <td>284.80</td>\n",
       "      <td>280.32</td>\n",
       "      <td>283.97</td>\n",
       "      <td>45780320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>231114</td>\n",
       "      <td>283.66</td>\n",
       "      <td>283.88</td>\n",
       "      <td>280.54</td>\n",
       "      <td>280.87</td>\n",
       "      <td>40350240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>231115</td>\n",
       "      <td>280.87</td>\n",
       "      <td>283.93</td>\n",
       "      <td>278.51</td>\n",
       "      <td>282.89</td>\n",
       "      <td>41784490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>231116</td>\n",
       "      <td>282.40</td>\n",
       "      <td>283.69</td>\n",
       "      <td>279.56</td>\n",
       "      <td>279.70</td>\n",
       "      <td>24654700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>231117</td>\n",
       "      <td>279.69</td>\n",
       "      <td>282.50</td>\n",
       "      <td>278.66</td>\n",
       "      <td>281.60</td>\n",
       "      <td>31282610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   <DATE>  <OPEN>  <HIGH>   <LOW>  <CLOSE>     <VOL>\n",
       "0  231108  273.53  278.35  273.28   278.15  58000060\n",
       "1  231109  278.60  278.85  276.02   276.65  28258660\n",
       "2  231110  276.99  281.30  276.60   280.19  44600220\n",
       "3  231113  280.40  284.80  280.32   283.97  45780320\n",
       "4  231114  283.66  283.88  280.54   280.87  40350240\n",
       "5  231115  280.87  283.93  278.51   282.89  41784490\n",
       "6  231116  282.40  283.69  279.56   279.70  24654700\n",
       "7  231117  279.69  282.50  278.66   281.60  31282610"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.csv',sep=';')\n",
    "test_data.drop(['<TICKER>','<PER>','<TIME>'],axis=1,inplace=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;DATE&gt;</th>\n",
       "      <th>&lt;OPEN&gt;</th>\n",
       "      <th>&lt;HIGH&gt;</th>\n",
       "      <th>&lt;LOW&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;</th>\n",
       "      <th>&lt;VOL&gt;</th>\n",
       "      <th>&lt;CLOSE&gt;_1d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_2d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_3d_ago</th>\n",
       "      <th>&lt;CLOSE&gt;_4d_ago</th>\n",
       "      <th>...</th>\n",
       "      <th>&lt;LOW&gt;_1d_ago</th>\n",
       "      <th>&lt;LOW&gt;_2d_ago</th>\n",
       "      <th>&lt;LOW&gt;_3d_ago</th>\n",
       "      <th>&lt;LOW&gt;_4d_ago</th>\n",
       "      <th>&lt;LOW&gt;_5d_ago</th>\n",
       "      <th>&lt;VOL&gt;_1d_ago</th>\n",
       "      <th>&lt;VOL&gt;_2d_ago</th>\n",
       "      <th>&lt;VOL&gt;_3d_ago</th>\n",
       "      <th>&lt;VOL&gt;_4d_ago</th>\n",
       "      <th>&lt;VOL&gt;_5d_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-11-15</td>\n",
       "      <td>280.87</td>\n",
       "      <td>283.93</td>\n",
       "      <td>278.51</td>\n",
       "      <td>282.89</td>\n",
       "      <td>41784490</td>\n",
       "      <td>280.87</td>\n",
       "      <td>283.97</td>\n",
       "      <td>280.19</td>\n",
       "      <td>276.65</td>\n",
       "      <td>...</td>\n",
       "      <td>280.54</td>\n",
       "      <td>280.32</td>\n",
       "      <td>276.60</td>\n",
       "      <td>276.02</td>\n",
       "      <td>273.28</td>\n",
       "      <td>40350240.0</td>\n",
       "      <td>45780320.0</td>\n",
       "      <td>44600220.0</td>\n",
       "      <td>28258660.0</td>\n",
       "      <td>58000060.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>282.40</td>\n",
       "      <td>283.69</td>\n",
       "      <td>279.56</td>\n",
       "      <td>279.70</td>\n",
       "      <td>24654700</td>\n",
       "      <td>282.89</td>\n",
       "      <td>280.87</td>\n",
       "      <td>283.97</td>\n",
       "      <td>280.19</td>\n",
       "      <td>...</td>\n",
       "      <td>278.51</td>\n",
       "      <td>280.54</td>\n",
       "      <td>280.32</td>\n",
       "      <td>276.60</td>\n",
       "      <td>276.02</td>\n",
       "      <td>41784490.0</td>\n",
       "      <td>40350240.0</td>\n",
       "      <td>45780320.0</td>\n",
       "      <td>44600220.0</td>\n",
       "      <td>28258660.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>279.69</td>\n",
       "      <td>282.50</td>\n",
       "      <td>278.66</td>\n",
       "      <td>281.60</td>\n",
       "      <td>31282610</td>\n",
       "      <td>279.70</td>\n",
       "      <td>282.89</td>\n",
       "      <td>280.87</td>\n",
       "      <td>283.97</td>\n",
       "      <td>...</td>\n",
       "      <td>279.56</td>\n",
       "      <td>278.51</td>\n",
       "      <td>280.54</td>\n",
       "      <td>280.32</td>\n",
       "      <td>276.60</td>\n",
       "      <td>24654700.0</td>\n",
       "      <td>41784490.0</td>\n",
       "      <td>40350240.0</td>\n",
       "      <td>45780320.0</td>\n",
       "      <td>44600220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      <DATE>  <OPEN>  <HIGH>   <LOW>  <CLOSE>     <VOL>  <CLOSE>_1d_ago  \\\n",
       "5 2023-11-15  280.87  283.93  278.51   282.89  41784490          280.87   \n",
       "6 2023-11-16  282.40  283.69  279.56   279.70  24654700          282.89   \n",
       "7 2023-11-17  279.69  282.50  278.66   281.60  31282610          279.70   \n",
       "\n",
       "   <CLOSE>_2d_ago  <CLOSE>_3d_ago  <CLOSE>_4d_ago  ...  <LOW>_1d_ago  \\\n",
       "5          283.97          280.19          276.65  ...        280.54   \n",
       "6          280.87          283.97          280.19  ...        278.51   \n",
       "7          282.89          280.87          283.97  ...        279.56   \n",
       "\n",
       "   <LOW>_2d_ago  <LOW>_3d_ago  <LOW>_4d_ago  <LOW>_5d_ago  <VOL>_1d_ago  \\\n",
       "5        280.32        276.60        276.02        273.28    40350240.0   \n",
       "6        280.54        280.32        276.60        276.02    41784490.0   \n",
       "7        278.51        280.54        280.32        276.60    24654700.0   \n",
       "\n",
       "   <VOL>_2d_ago  <VOL>_3d_ago  <VOL>_4d_ago  <VOL>_5d_ago  \n",
       "5    45780320.0    44600220.0    28258660.0    58000060.0  \n",
       "6    40350240.0    45780320.0    44600220.0    28258660.0  \n",
       "7    41784490.0    40350240.0    45780320.0    44600220.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Преобразование столбца с датой в формат datetime\n",
    "test_data['<DATE>'] = pd.to_datetime(test_data['<DATE>'], format='%y%m%d')\n",
    "\n",
    "# Сортировка данных по столбцу с датой\n",
    "test_data = test_data.sort_values(by='<DATE>')\n",
    "\n",
    "# Добавление значений за пять дней назад для каждого столбца\n",
    "columns_to_shift = ['<CLOSE>', '<HIGH>', '<LOW>', '<VOL>']\n",
    "for col in columns_to_shift:\n",
    "    for i in range(1, 6):\n",
    "        test_data[f'{col}_{i}d_ago'] = test_data[col].shift(i)\n",
    "\n",
    "# Вывод измененного DataFrame\n",
    "test_data.dropna(inplace=True)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7000065e+18, 2.8087000e+02, 2.8397000e+02, 2.8019000e+02,\n",
       "        2.7664999e+02, 2.7814999e+02, 2.8388000e+02, 2.8479999e+02,\n",
       "        2.8129999e+02, 2.7885001e+02, 2.7835001e+02, 2.8054001e+02,\n",
       "        2.8032001e+02, 2.7660001e+02, 2.7601999e+02, 2.7328000e+02,\n",
       "        4.0350240e+07, 4.5780320e+07, 4.4600220e+07, 2.8258660e+07,\n",
       "        5.8000060e+07],\n",
       "       [1.7000928e+18, 2.8289001e+02, 2.8087000e+02, 2.8397000e+02,\n",
       "        2.8019000e+02, 2.7664999e+02, 2.8392999e+02, 2.8388000e+02,\n",
       "        2.8479999e+02, 2.8129999e+02, 2.7885001e+02, 2.7851001e+02,\n",
       "        2.8054001e+02, 2.8032001e+02, 2.7660001e+02, 2.7601999e+02,\n",
       "        4.1784488e+07, 4.0350240e+07, 4.5780320e+07, 4.4600220e+07,\n",
       "        2.8258660e+07],\n",
       "       [1.7001792e+18, 2.7970001e+02, 2.8289001e+02, 2.8087000e+02,\n",
       "        2.8397000e+02, 2.8019000e+02, 2.8369000e+02, 2.8392999e+02,\n",
       "        2.8388000e+02, 2.8479999e+02, 2.8129999e+02, 2.7956000e+02,\n",
       "        2.7851001e+02, 2.8054001e+02, 2.8032001e+02, 2.7660001e+02,\n",
       "        2.4654700e+07, 4.1784488e+07, 4.0350240e+07, 4.5780320e+07,\n",
       "        4.4600220e+07]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test_data = torch.tensor(test_data['<CLOSE>'].values, dtype=torch.float32).view(-1, 1)\n",
    "test_data.drop(['<CLOSE>','<OPEN>','<HIGH>','<LOW>','<VOL>'],axis=1,inplace=True)\n",
    "test_data['<DATE>'] = pd.to_datetime(test_data['<DATE>']).astype(np.int64)\n",
    "test_data.dtypes\n",
    "test_data = test_data.values.astype('float32')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(test_input)\n",
    "\n",
    "predicted_values = test_outputs.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicted_values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming fc_series contains your predicted values and y_test contains your actual test values\n",
    "\n",
    "# Plotting predicted values and actual test values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(predicted_values, label='Predicted Values', color='orange')\n",
    "plt.plot(y_test, label='Actual Values', color='blue')\n",
    "\n",
    "plt.title('Predicted vs Actual Values')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
